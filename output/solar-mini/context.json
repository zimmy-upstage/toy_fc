[
    "Building Solar Mini. Fundamentals. The foundational architecture of Solar Mini is based on a 32-layer Llama 2 structure, and is initialized with pre-trained weights from Mistral 7B, one of the best-performing models compatible with the Llama 2 architecture. Depth Up-scaling (DUS) How did Solar Mini Solar Mini stay compact, yet become remarkably ..., title: Introducing Solar Mini : Compact yet Powerful \u2014 Upstage, link: https://www.upstage.ai/feed/product/solarmini-performance-report, ",
    "We introduce SOLAR 10.7B, a large language model (LLM) with 10.7 billion parameters, demonstrating superior performance in various natural language processing (NLP) tasks. Inspired by recent efforts to efficiently up-scale LLMs, we present a method for scaling LLMs called depth up-scaling (DUS), which encompasses depthwise scaling and continued pretraining. In contrast to other LLM up-scaling ..., title: SOLAR 10.7B: Scaling Large Language Models with Simple yet Effective ..., link: https://arxiv.org/abs/2312.15166, ",
    "Utilizing a unique depth up-scaling technique based on open-source 7B models, Solar 10.7B surpassed all models on the Open LLM Leaderboard, with an average score of 74.2. ... (SLM) category. Despite its compact size, the depth-up-scaled Solar 10.7B has outperformed renowned pre-trained models by major tech giants, surpassing benchmarks set by ..., title: Upstage's Solar 10.7B Emerges as World's Top Pre-trained LLM, link: https://www.upstage.ai/feed/press/solar-10-7b-emerges-as-worlds-top-pre-trained-llm, ",
    "2023/12/14. Upstage LLM 'Solar' released, ranked first in the world on the 'Hugging Face Open LLM Leaderboard' along with the announcement. THE WORLD'S FIRST SMALL MODEL WITH 10.7B PARAMETERS BECAME THE GLOBAL TOP GENERATING AI MODEL. BOTH A PRE-LEARNING MODEL CAPABLE OF ADDITIONAL LEARNING AND A FINE TUNING MODEL WITH HIGH PRACTICAL USABILITY ..., title: Upstage's Solar 10.7B Emerges as World's Top Pre-trained LLM, link: https://en.content.upstage.ai/newsroom/solar10b-huggingface-no1"
]